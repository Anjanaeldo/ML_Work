{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment Alternus Vera - Fake News Classifier\n",
    "\n",
    "#### Team Psychic Pandas\n",
    "\n",
    "#### Factor for analysing fake news - Sensationalism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '/Users/andrew/Documents/MS - SJSU/Fall Sem 2018/CMPE 257 - Machine Learning/liar_dataset'\n",
    "TRAIN_PATH = '/train.tsv'\n",
    "TEST_PATH = '/test.tsv'\n",
    "train_df_1 = pd.read_csv(DATA_FOLDER+TRAIN_PATH,sep='\\t', header = None)\n",
    "test_df = pd.read_csv(DATA_FOLDER+TEST_PATH,sep='\\t', header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naming the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_1.columns = [\"id\", \"label\", \"statement\", \"subject\", \"speaker\", \"speaker_title\", \"State\", \"party_affiliation\", \"barely_true\", \"false\", \"half_true\", \"mostly_true\", \"pants_on_fire\",\"context\"]\n",
    "test_df.columns = [\"id\", \"label\", \"statement\", \"subject\", \"speaker\", \"speaker_title\", \"State\", \"party_affiliation\", \"barely_true\", \"false\", \"half_true\", \"mostly_true\", \"pants_on_fire\",\"context\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_title</th>\n",
       "      <th>State</th>\n",
       "      <th>party_affiliation</th>\n",
       "      <th>barely_true</th>\n",
       "      <th>false</th>\n",
       "      <th>half_true</th>\n",
       "      <th>mostly_true</th>\n",
       "      <th>pants_on_fire</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2635.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a mailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10540.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>State delegate</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a floor speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324.json</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>foreign-policy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1123.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>blog-posting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>a news release</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9028.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>economy,jobs</td>\n",
       "      <td>charlie-crist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Florida</td>\n",
       "      <td>democrat</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>an interview on CNN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        label                                          statement  \\\n",
       "0   2635.json        false  Says the Annies List political group supports ...   \n",
       "1  10540.json    half-true  When did the decline of coal start? It started...   \n",
       "2    324.json  mostly-true  Hillary Clinton agrees with John McCain \"by vo...   \n",
       "3   1123.json        false  Health care reform legislation is likely to ma...   \n",
       "4   9028.json    half-true  The economic turnaround started at the end of ...   \n",
       "\n",
       "                              subject         speaker         speaker_title  \\\n",
       "0                            abortion    dwayne-bohac  State representative   \n",
       "1  energy,history,job-accomplishments  scott-surovell        State delegate   \n",
       "2                      foreign-policy    barack-obama             President   \n",
       "3                         health-care    blog-posting                   NaN   \n",
       "4                        economy,jobs   charlie-crist                   NaN   \n",
       "\n",
       "      State party_affiliation  barely_true  false  half_true  mostly_true  \\\n",
       "0     Texas        republican          0.0    1.0        0.0          0.0   \n",
       "1  Virginia          democrat          0.0    0.0        1.0          1.0   \n",
       "2  Illinois          democrat         70.0   71.0      160.0        163.0   \n",
       "3       NaN              none          7.0   19.0        3.0          5.0   \n",
       "4   Florida          democrat         15.0    9.0       20.0         19.0   \n",
       "\n",
       "   pants_on_fire              context  \n",
       "0            0.0             a mailer  \n",
       "1            0.0      a floor speech.  \n",
       "2            9.0               Denver  \n",
       "3           44.0       a news release  \n",
       "4            2.0  an interview on CNN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Building a wall on the U.S.-Mexico border will...\n",
       "1       Wisconsin is on pace to double the number of l...\n",
       "2       Says John McCain has done nothing to help the ...\n",
       "3       Suzanne Bonamici supports a plan that will cut...\n",
       "4       When asked by a reporter whether hes at the ce...\n",
       "5       Over the past five years the federal governmen...\n",
       "6       Says that Tennessee law requires that schools ...\n",
       "7       Says Vice President Joe Biden \"admits that the...\n",
       "8       Donald Trump is against marriage equality. He ...\n",
       "9       We know that more than half of Hillary Clinton...\n",
       "10      We know there are more Democrats in Georgia th...\n",
       "11      PolitiFact Texas says Congressman Edwards atta...\n",
       "12             Denali is the Kenyan word for black power.\n",
       "13      Says 57 percent of federal spending goes to th...\n",
       "14           On residency requirements for public workers\n",
       "15      Says the unemployment rate for college graduat...\n",
       "16      Unfortunately we have documented instances whe...\n",
       "17      A recent Gallup poll found that 72 percent of ...\n",
       "18      Each year, 18,000 people die in America becaus...\n",
       "19      Ronald Reagan faced an even worse recession th...\n",
       "20      There have not been any public safety issues i...\n",
       "21      Says Mitt Romney was one of the first national...\n",
       "22      The number of illegal immigrants could be 3 mi...\n",
       "23                  Marijuana is less toxic than alcohol.\n",
       "24      Says Charlie Crist is embroiled in a fraud cas...\n",
       "25      Now, there was a time when someone like Scalia...\n",
       "26      I was gone when there was a red line against S...\n",
       "27      Tim Kaine hiked tuition as governor, but now c...\n",
       "28      Contends that President Obama literally said (...\n",
       "29      Active duty males in the military are twice as...\n",
       "                              ...                        \n",
       "1237    Says the cascading effects of climate change c...\n",
       "1238    Says state Rep. Sandy Pasch, her recall oppone...\n",
       "1239    Barack Obama \"rejects everyone white, includin...\n",
       "1240    A company hired to do Common Core testing in F...\n",
       "1241    The U.S. Supreme Court has not traditionally a...\n",
       "1242    Fracturing or horizontally fracturing the shal...\n",
       "1243    In 2004, \"20 percent of U.S. households were g...\n",
       "1244    We are now eighth in the nation in job creatio...\n",
       "1245    In Europe, church attendance rates (are) in th...\n",
       "1246    Says George LeMieux even compared Marco Rubio ...\n",
       "1247    Says Barack Obama promised to halve the defici...\n",
       "1248    Says the government has gotten the TARP money ...\n",
       "1249    Points of Light is the worlds largest voluntee...\n",
       "1250    Says Mark Pryorcut Medicare to pay for Obamacare.\n",
       "1251    Says Tim Kaine actually tried to raise taxes b...\n",
       "1252    Says Marco Rubio is proposing a new $1 trillio...\n",
       "1253    I am the only senator who turned down the stat...\n",
       "1254                        Female buffalo lead the herd.\n",
       "1255    There is no system to vet refugees from the Mi...\n",
       "1256    Says Chris Christies plan to kick-start our ec...\n",
       "1257    Obama used $20 million in federal money to emm...\n",
       "1258                                On offshore drilling.\n",
       "1259    We came out of the White House not only dead b...\n",
       "1260    I think its seven or eight of the California s...\n",
       "1261    Sen. Bob Menendez voted to enact a new tax on ...\n",
       "1262    Says his budget provides the highest state fun...\n",
       "1263                      Ive been here almost every day.\n",
       "1264    In the early 1980s, Sen. Edward Kennedy secret...\n",
       "1265    Says an EPA permit languished under Strickland...\n",
       "1266    Says the governor is going around the state ta...\n",
       "Name: statement, Length: 1267, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['statement']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking statements from dataset and assigning index to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "statement = train_df_1[['statement']]\n",
    "statement['index'] = statement.index\n",
    "statement_news = statement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10240\n",
      "                                           statement  index\n",
      "0  Says the Annies List political group supports ...      0\n",
      "1  When did the decline of coal start? It started...      1\n",
      "2  Hillary Clinton agrees with John McCain \"by vo...      2\n",
      "3  Health care reform legislation is likely to ma...      3\n",
      "4  The economic turnaround started at the end of ...      4\n"
     ]
    }
   ],
   "source": [
    "### printing the length of the entire dataset of statements\n",
    "print(len(statement_news))\n",
    "print(statement_news[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "* Next step is to prepare the data by removing all punctuations,stopwords etc\n",
    "* At first, tokenization is applied to split the text we have just got to sentences and then sentences to words.\n",
    "* Next, it is converted to lowercase\n",
    "* Then Lemmatization is applied to change all past and future words to present and also changes words with third person to first\n",
    "* Next step os to apply Stemming whre words are changed to their root form\n",
    "\n",
    "* For preprocessing, genism library is imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/andrew/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to carry out lemmetization and stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    stemmer = PorterStemmer()\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Have taken an article to test lemmatization and stemming done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original document: \n",
      "['Members', 'of', 'the', 'public', 'are', 'being', 'charged', '$50', 'to', 'hear', 'Gov.', 'Scott', 'Walker', 'and', 'a', 'dozen', 'members', 'of', 'his', 'administration', 'talk', 'about', 'jobs', 'and', 'the', 'economy', 'at', 'Lambeau', 'Field.']\n",
      "\n",
      "\n",
      " tokenized and lemmatized document: \n",
      "['member', 'public', 'charg', 'hear', 'scott', 'walker', 'dozen', 'member', 'administr', 'talk', 'job', 'economi', 'lambeau', 'field']\n"
     ]
    }
   ],
   "source": [
    "doc_sample = statement_news[statement_news['index'] == 4310].values[0][0]\n",
    "print('original document: ')\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing all the articles in the set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [say, anni, list, polit, group, support, trime...\n",
       "1    [declin, coal, start, start, natur, take, star...\n",
       "2    [hillari, clinton, agre, john, mccain, vote, g...\n",
       "3    [health, care, reform, legisl, like, mandat, f...\n",
       "4                    [econom, turnaround, start, term]\n",
       "5    [chicago, bear, start, quarterback, year, tota...\n",
       "6               [dunnam, live, district, repres, year]\n",
       "7    [person, stage, work, activ, year, pass, russ,...\n",
       "8    [take, million, oregon, lotteri, fund, port, n...\n",
       "9    [say, primari, oppon, glenn, grothman, leibham...\n",
       "Name: statement, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_statement = statement_news['statement'].map(preprocess)\n",
    "processed_statement[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bags of words on the processed dataset\n",
    "\n",
    "* Creating a dictionary of words from the processed data that we got above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 abort\n",
      "1 anni\n",
      "2 demand\n",
      "3 group\n",
      "4 list\n",
      "5 polit\n",
      "6 say\n",
      "7 support\n",
      "8 trimest\n",
      "9 administr\n",
      "10 begin\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_statement)\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Keeping only the most frequent words\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using bow2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7, 1),\n",
       " (85, 1),\n",
       " (127, 1),\n",
       " (128, 1),\n",
       " (181, 2),\n",
       " (252, 1),\n",
       " (275, 1),\n",
       " (322, 1),\n",
       " (540, 1),\n",
       " (790, 1),\n",
       " (1019, 1)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_statement]\n",
    "bow_corpus[4310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 7 (\"administr\") appears 1 time.\n",
      "Word 85 (\"economi\") appears 1 time.\n",
      "Word 127 (\"scott\") appears 1 time.\n",
      "Word 128 (\"walker\") appears 1 time.\n",
      "Word 181 (\"member\") appears 2 time.\n",
      "Word 252 (\"job\") appears 1 time.\n",
      "Word 275 (\"public\") appears 1 time.\n",
      "Word 322 (\"hear\") appears 1 time.\n",
      "Word 540 (\"charg\") appears 1 time.\n",
      "Word 790 (\"talk\") appears 1 time.\n",
      "Word 1019 (\"field\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "bow_doc_4310 = bow_corpus[4310]\n",
    "for i in range(len(bow_doc_4310)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0], \n",
    "                                               dictionary[bow_doc_4310[i][0]], \n",
    "bow_doc_4310[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying TF-IDF to bow_corpus "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.3397402827336795),\n",
      " (1, 0.5002880765433487),\n",
      " (2, 0.4088224168287155),\n",
      " (3, 0.4639566513984633),\n",
      " (4, 0.40750764496407926),\n",
      " (5, 0.10879086838115597),\n",
      " (6, 0.27202739591951525)]\n"
     ]
    }
   ],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]\n",
    "from pprint import pprint\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying LDA for Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.046*\"say\" + 0.029*\"texa\" + 0.024*\"state\" + 0.021*\"american\" + 0.015*\"job\" + 0.013*\"million\" + 0.011*\"vote\" + 0.010*\"time\" + 0.010*\"school\" + 0.010*\"percent\"\n",
      "Topic: 1 \n",
      "Words: 0.030*\"state\" + 0.028*\"say\" + 0.021*\"job\" + 0.019*\"percent\" + 0.017*\"nation\" + 0.017*\"counti\" + 0.016*\"year\" + 0.013*\"rate\" + 0.012*\"presid\" + 0.010*\"creat\"\n",
      "Topic: 2 \n",
      "Words: 0.055*\"say\" + 0.030*\"obama\" + 0.024*\"presid\" + 0.015*\"percent\" + 0.015*\"barack\" + 0.014*\"state\" + 0.014*\"secur\" + 0.012*\"support\" + 0.012*\"social\" + 0.009*\"citi\"\n",
      "Topic: 3 \n",
      "Words: 0.044*\"year\" + 0.027*\"say\" + 0.023*\"percent\" + 0.018*\"illeg\" + 0.016*\"state\" + 0.015*\"immigr\" + 0.013*\"elect\" + 0.011*\"school\" + 0.010*\"budget\" + 0.009*\"vote\"\n",
      "Topic: 4 \n",
      "Words: 0.032*\"say\" + 0.029*\"state\" + 0.022*\"vote\" + 0.020*\"peopl\" + 0.016*\"percent\" + 0.012*\"unit\" + 0.012*\"spend\" + 0.011*\"clinton\" + 0.011*\"cut\" + 0.011*\"countri\"\n",
      "Topic: 5 \n",
      "Words: 0.043*\"say\" + 0.039*\"vote\" + 0.018*\"percent\" + 0.015*\"time\" + 0.011*\"right\" + 0.010*\"state\" + 0.010*\"compani\" + 0.010*\"feder\" + 0.009*\"like\" + 0.009*\"island\"\n",
      "Topic: 6 \n",
      "Words: 0.036*\"say\" + 0.036*\"year\" + 0.029*\"health\" + 0.024*\"care\" + 0.017*\"obama\" + 0.016*\"peopl\" + 0.014*\"tax\" + 0.014*\"percent\" + 0.014*\"plan\" + 0.012*\"increas\"\n",
      "Topic: 7 \n",
      "Words: 0.034*\"say\" + 0.026*\"obama\" + 0.026*\"percent\" + 0.021*\"presid\" + 0.015*\"health\" + 0.013*\"barack\" + 0.013*\"american\" + 0.012*\"year\" + 0.012*\"countri\" + 0.011*\"republican\"\n",
      "Topic: 8 \n",
      "Words: 0.030*\"say\" + 0.021*\"percent\" + 0.018*\"state\" + 0.017*\"offic\" + 0.012*\"support\" + 0.011*\"averag\" + 0.011*\"candid\" + 0.011*\"tax\" + 0.010*\"budget\" + 0.010*\"take\"\n",
      "Topic: 9 \n",
      "Words: 0.036*\"say\" + 0.034*\"state\" + 0.027*\"million\" + 0.021*\"billion\" + 0.019*\"year\" + 0.017*\"spend\" + 0.015*\"govern\" + 0.013*\"job\" + 0.011*\"feder\" + 0.010*\"obama\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying LDA on TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.012*\"say\" + 0.011*\"state\" + 0.008*\"dont\" + 0.008*\"year\" + 0.007*\"democrat\" + 0.007*\"govern\" + 0.007*\"care\" + 0.007*\"spend\" + 0.007*\"vote\" + 0.007*\"republican\"\n",
      "Topic: 1 Word: 0.014*\"year\" + 0.011*\"say\" + 0.011*\"percent\" + 0.011*\"state\" + 0.009*\"dollar\" + 0.009*\"spend\" + 0.008*\"million\" + 0.007*\"school\" + 0.007*\"govern\" + 0.006*\"cost\"\n",
      "Topic: 2 Word: 0.014*\"say\" + 0.013*\"job\" + 0.011*\"illeg\" + 0.010*\"creat\" + 0.009*\"obama\" + 0.009*\"year\" + 0.009*\"secur\" + 0.009*\"campaign\" + 0.009*\"immigr\" + 0.009*\"presid\"\n",
      "Topic: 3 Word: 0.017*\"say\" + 0.010*\"state\" + 0.009*\"texa\" + 0.008*\"year\" + 0.008*\"nation\" + 0.007*\"countri\" + 0.007*\"billion\" + 0.007*\"number\" + 0.007*\"percent\" + 0.006*\"presid\"\n",
      "Topic: 4 Word: 0.013*\"say\" + 0.012*\"percent\" + 0.008*\"romney\" + 0.008*\"countri\" + 0.008*\"school\" + 0.008*\"million\" + 0.008*\"health\" + 0.007*\"tax\" + 0.007*\"year\" + 0.007*\"mitt\"\n",
      "Topic: 5 Word: 0.014*\"say\" + 0.013*\"state\" + 0.010*\"obama\" + 0.010*\"year\" + 0.009*\"plan\" + 0.008*\"immigr\" + 0.007*\"student\" + 0.007*\"illeg\" + 0.007*\"percent\" + 0.007*\"deficit\"\n",
      "Topic: 6 Word: 0.015*\"obama\" + 0.012*\"year\" + 0.012*\"republican\" + 0.012*\"state\" + 0.011*\"billion\" + 0.011*\"vote\" + 0.010*\"presid\" + 0.010*\"say\" + 0.010*\"barack\" + 0.008*\"budget\"\n",
      "Topic: 7 Word: 0.015*\"say\" + 0.010*\"american\" + 0.009*\"state\" + 0.009*\"tri\" + 0.009*\"presid\" + 0.009*\"clinton\" + 0.009*\"obama\" + 0.009*\"unemploy\" + 0.009*\"hillari\" + 0.009*\"know\"\n",
      "Topic: 8 Word: 0.015*\"percent\" + 0.013*\"health\" + 0.012*\"say\" + 0.011*\"care\" + 0.009*\"obamacar\" + 0.009*\"cost\" + 0.008*\"america\" + 0.008*\"peopl\" + 0.008*\"million\" + 0.007*\"fund\"\n",
      "Topic: 9 Word: 0.017*\"percent\" + 0.014*\"tax\" + 0.012*\"state\" + 0.011*\"year\" + 0.010*\"say\" + 0.009*\"health\" + 0.008*\"increas\" + 0.008*\"world\" + 0.008*\"nation\" + 0.007*\"vote\"\n"
     ]
    }
   ],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['member',\n",
       " 'public',\n",
       " 'charg',\n",
       " 'hear',\n",
       " 'scott',\n",
       " 'walker',\n",
       " 'dozen',\n",
       " 'member',\n",
       " 'administr',\n",
       " 'talk',\n",
       " 'job',\n",
       " 'economi',\n",
       " 'lambeau',\n",
       " 'field']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_statement[4310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.9307518601417542\t \n",
      "Topic: 0.030*\"state\" + 0.028*\"say\" + 0.021*\"job\" + 0.019*\"percent\" + 0.017*\"nation\" + 0.017*\"counti\" + 0.016*\"year\" + 0.013*\"rate\" + 0.012*\"presid\" + 0.010*\"creat\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LDA on Bag of words gave an evaluation of 93%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.9307539463043213\t \n",
      "Topic: 0.015*\"say\" + 0.010*\"american\" + 0.009*\"state\" + 0.009*\"tri\" + 0.009*\"presid\" + 0.009*\"clinton\" + 0.009*\"obama\" + 0.009*\"unemploy\" + 0.009*\"hillari\" + 0.009*\"know\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model_tfidf[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA on Bag of words also gave an evaluation of 93%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on an unseen document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Over the past five years the federal government has paid out $601 million in retirement and disability benefits to deceased former federal employees.'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['statement'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.6009959578514099\t Topic: 0.044*\"year\" + 0.027*\"say\" + 0.023*\"percent\" + 0.018*\"illeg\" + 0.016*\"state\"\n",
      "Score: 0.3323208689689636\t Topic: 0.036*\"say\" + 0.034*\"state\" + 0.027*\"million\" + 0.021*\"billion\" + 0.019*\"year\"\n"
     ]
    }
   ],
   "source": [
    "unseen_document = test_df['statement'][5]\n",
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Factor Sensationalism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensationalist_phrases_vocab = [\n",
    "'Assassination',\n",
    "'Attack',\n",
    "'Domestic security',\n",
    "'Law enforcement',\n",
    "'Disaster',\n",
    "'National preparedness',\n",
    "'Response',\n",
    "'Recovery',\n",
    "'Emergency response',\n",
    "'First responder',\n",
    "'Militia',\n",
    "'Shooting',\n",
    "'Evacuation',\n",
    "'Hostage',\n",
    "'Explosion',\n",
    "'Organized crime',\n",
    "'Gangs',\n",
    "'National security',\n",
    "'State of emergency',\n",
    "'Security breach',\n",
    "'Threat',\n",
    "'Standoff',\n",
    "'Lockdown',\n",
    "'Bomb',\n",
    "'Riot',\n",
    "'Emergency Landing',\n",
    "'Incident',\n",
    "'Suspicious',\n",
    "'Nuclear threat',\n",
    "'Hazardous',\n",
    "'Infection',\n",
    "'Outbreak',\n",
    "'Contamination',\n",
    "'Terror',\n",
    "'Epidemic',\n",
    "'Critical Infrastructure',\n",
    "'National infrastructure',\n",
    "'Transportation security',\n",
    "'Grid',\n",
    "'Outage',\n",
    "'Disruption',\n",
    "'Violence',\n",
    "'Drug cartel',\n",
    "'Narcotics',\n",
    "'Shootout',\n",
    "'Trafficking',\n",
    "'Kidnap',\n",
    "'Illegal',\n",
    "'Smuggling', \n",
    "'Al Qaeda',\n",
    "'Terror attack',\n",
    "'Weapon',\n",
    "'Improvised explosive device',\n",
    "'Suicide bomber',\n",
    "'Suicide attack',\n",
    "'Hurricane',\n",
    "'Tornado',\n",
    "'Tsunami',\n",
    "'Earthquake',\n",
    "'Tremor',\n",
    "'Flood',\n",
    "'Storm',\n",
    "'Extreme weather',\n",
    "'Forest fire',\n",
    "'Ice',\n",
    "'Stranded',\n",
    "'Wildfire',\n",
    "'Avalanche',\n",
    "'Blizzard',\n",
    "'Lightening',\n",
    "'Emergency Broadcast System',\n",
    "'Cyber Security',\n",
    "'DDOS',\n",
    "'Denial of service',\n",
    "'Malware',\n",
    "'Phishing',\n",
    "'Cyber attack',\n",
    "'Cyber terror',\n",
    "'believe',\n",
    "'support',\n",
    "'ISIS',\n",
    "'absolutely',\n",
    "'promise',\n",
    "'society',\n",
    "'FBI',\n",
    "'declare',\n",
    "'war',\n",
    "'islam',\n",
    "'recession',\n",
    "'price',\n",
    "'stock market',\n",
    "'lottery',\n",
    "'terror',\n",
    "'sanctoin',\n",
    "'ban',\n",
    "'signed',\n",
    "'climate change',\n",
    "'global warming',\n",
    "'killed',\n",
    "'shooting',\n",
    "'gun fire',\n",
    "'nuclear',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensationalist_phrases_dict = {k: v for v, k in enumerate(sensationalist_phrases_vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Assassination': 0,\n",
       " 'Attack': 1,\n",
       " 'Domestic security': 2,\n",
       " 'Law enforcement': 3,\n",
       " 'Disaster': 4,\n",
       " 'National preparedness': 5,\n",
       " 'Response': 6,\n",
       " 'Recovery': 7,\n",
       " 'Emergency response': 8,\n",
       " 'First responder': 9,\n",
       " 'Militia': 10,\n",
       " 'Shooting': 11,\n",
       " 'Evacuation': 12,\n",
       " 'Hostage': 13,\n",
       " 'Explosion': 14,\n",
       " 'Organized crime': 15,\n",
       " 'Gangs': 16,\n",
       " 'National security': 17,\n",
       " 'State of emergency': 18,\n",
       " 'Security breach': 19,\n",
       " 'Threat': 20,\n",
       " 'Standoff': 21,\n",
       " 'Lockdown': 22,\n",
       " 'Bomb': 23,\n",
       " 'Riot': 24,\n",
       " 'Emergency Landing': 25,\n",
       " 'Incident': 26,\n",
       " 'Suspicious': 27,\n",
       " 'Nuclear threat': 28,\n",
       " 'Hazardous': 29,\n",
       " 'Infection': 30,\n",
       " 'Outbreak': 31,\n",
       " 'Contamination': 32,\n",
       " 'Terror': 33,\n",
       " 'Epidemic': 34,\n",
       " 'Critical Infrastructure': 35,\n",
       " 'National infrastructure': 36,\n",
       " 'Transportation security': 37,\n",
       " 'Grid': 38,\n",
       " 'Outage': 39,\n",
       " 'Disruption': 40,\n",
       " 'Violence': 41,\n",
       " 'Drug cartel': 42,\n",
       " 'Narcotics': 43,\n",
       " 'Shootout': 44,\n",
       " 'Trafficking': 45,\n",
       " 'Kidnap': 46,\n",
       " 'Illegal': 47,\n",
       " 'Smuggling': 48,\n",
       " 'Al Qaeda': 49,\n",
       " 'Terror attack': 50,\n",
       " 'Weapon': 51,\n",
       " 'Improvised explosive device': 52,\n",
       " 'Suicide bomber': 53,\n",
       " 'Suicide attack': 54,\n",
       " 'Hurricane': 55,\n",
       " 'Tornado': 56,\n",
       " 'Tsunami': 57,\n",
       " 'Earthquake': 58,\n",
       " 'Tremor': 59,\n",
       " 'Flood': 60,\n",
       " 'Storm': 61,\n",
       " 'Extreme weather': 62,\n",
       " 'Forest fire': 63,\n",
       " 'Ice': 64,\n",
       " 'Stranded': 65,\n",
       " 'Wildfire': 66,\n",
       " 'Avalanche': 67,\n",
       " 'Blizzard': 68,\n",
       " 'Lightening': 69,\n",
       " 'Emergency Broadcast System': 70,\n",
       " 'Cyber Security': 71,\n",
       " 'DDOS': 72,\n",
       " 'Denial of service': 73,\n",
       " 'Malware': 74,\n",
       " 'Phishing': 75,\n",
       " 'Cyber attack': 76,\n",
       " 'Cyber terror': 77,\n",
       " 'believe': 78,\n",
       " 'support': 79,\n",
       " 'ISIS': 80,\n",
       " 'absolutely': 81,\n",
       " 'promise': 82,\n",
       " 'society': 83,\n",
       " 'FBI': 84,\n",
       " 'declare': 85,\n",
       " 'war': 86,\n",
       " 'islam': 87,\n",
       " 'recession': 88,\n",
       " 'price': 89,\n",
       " 'stock market': 90,\n",
       " 'lottery': 91,\n",
       " 'terror': 92,\n",
       " 'sanctoin': 93,\n",
       " 'ban': 94,\n",
       " 'signed': 95,\n",
       " 'climate change': 96,\n",
       " 'global warming': 97,\n",
       " 'killed': 98,\n",
       " 'shooting': 99,\n",
       " 'gun fire': 100,\n",
       " 'nuclear': 101}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensationalist_phrases_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(DATA_FOLDER+TRAIN_PATH,sep='\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns = [\"id\", \"label\", \"statement\", \"subject\", \"speaker\", \"speaker_title\", \"State\", \"party_affiliation\", \"barely_true\", \"false\", \"half_true\", \"mostly_true\", \"pants_on_fire\",\"context\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statement</th>\n",
       "      <th>stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Says Annies List political group supports thir...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When decline coal start? It started natural ga...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hillary Clinton agrees John McCain \"by voting ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Health care reform legislation likely mandate ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The economic turnaround started end term.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           statement  stopwords\n",
       "0  Says Annies List political group supports thir...          0\n",
       "1  When decline coal start? It started natural ga...          0\n",
       "2  Hillary Clinton agrees John McCain \"by voting ...          0\n",
       "3  Health care reform legislation likely mandate ...          0\n",
       "4          The economic turnaround started end term.          0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "#nltk.download()\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "train_df_1['stopwords'] = train_df_1['statement'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "train_df_1[['statement','stopwords']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_title</th>\n",
       "      <th>State</th>\n",
       "      <th>party_affiliation</th>\n",
       "      <th>barely_true</th>\n",
       "      <th>false</th>\n",
       "      <th>half_true</th>\n",
       "      <th>mostly_true</th>\n",
       "      <th>pants_on_fire</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2635.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Says Annies List political group supports thir...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>dwayne-bohac</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a mailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10540.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>When decline coal start? It started natural ga...</td>\n",
       "      <td>energy,history,job-accomplishments</td>\n",
       "      <td>scott-surovell</td>\n",
       "      <td>State delegate</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>democrat</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>a floor speech.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>324.json</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Hillary Clinton agrees John McCain \"by voting ...</td>\n",
       "      <td>foreign-policy</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Denver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1123.json</td>\n",
       "      <td>false</td>\n",
       "      <td>Health care reform legislation likely mandate ...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>blog-posting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none</td>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>a news release</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9028.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>The economic turnaround started end term.</td>\n",
       "      <td>economy,jobs</td>\n",
       "      <td>charlie-crist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Florida</td>\n",
       "      <td>democrat</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>an interview on CNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12465.json</td>\n",
       "      <td>true</td>\n",
       "      <td>The Chicago Bears starting quarterbacks last 1...</td>\n",
       "      <td>education</td>\n",
       "      <td>robin-vos</td>\n",
       "      <td>Wisconsin Assembly speaker</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a an online opinion-piece</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2342.json</td>\n",
       "      <td>barely-true</td>\n",
       "      <td>Jim Dunnam lived district represents years now.</td>\n",
       "      <td>candidates-biography</td>\n",
       "      <td>republican-party-texas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Texas</td>\n",
       "      <td>republican</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a press release.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>153.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>I'm person stage worked actively last year pas...</td>\n",
       "      <td>ethics</td>\n",
       "      <td>barack-obama</td>\n",
       "      <td>President</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>democrat</td>\n",
       "      <td>70.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>a Democratic debate in Philadelphia, Pa.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5602.json</td>\n",
       "      <td>half-true</td>\n",
       "      <td>However, took $19.5 million Oregon Lottery fun...</td>\n",
       "      <td>jobs</td>\n",
       "      <td>oregon-lottery</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>organization</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9741.json</td>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Says GOP primary opponents Glenn Grothman Joe ...</td>\n",
       "      <td>energy,message-machine-2014,voting-record</td>\n",
       "      <td>duey-stroebel</td>\n",
       "      <td>State representative</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>republican</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>an online video</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        label                                          statement  \\\n",
       "0   2635.json        false  Says Annies List political group supports thir...   \n",
       "1  10540.json    half-true  When decline coal start? It started natural ga...   \n",
       "2    324.json  mostly-true  Hillary Clinton agrees John McCain \"by voting ...   \n",
       "3   1123.json        false  Health care reform legislation likely mandate ...   \n",
       "4   9028.json    half-true          The economic turnaround started end term.   \n",
       "5  12465.json         true  The Chicago Bears starting quarterbacks last 1...   \n",
       "6   2342.json  barely-true    Jim Dunnam lived district represents years now.   \n",
       "7    153.json    half-true  I'm person stage worked actively last year pas...   \n",
       "8   5602.json    half-true  However, took $19.5 million Oregon Lottery fun...   \n",
       "9   9741.json  mostly-true  Says GOP primary opponents Glenn Grothman Joe ...   \n",
       "\n",
       "                                     subject                 speaker  \\\n",
       "0                                   abortion            dwayne-bohac   \n",
       "1         energy,history,job-accomplishments          scott-surovell   \n",
       "2                             foreign-policy            barack-obama   \n",
       "3                                health-care            blog-posting   \n",
       "4                               economy,jobs           charlie-crist   \n",
       "5                                  education               robin-vos   \n",
       "6                       candidates-biography  republican-party-texas   \n",
       "7                                     ethics            barack-obama   \n",
       "8                                       jobs          oregon-lottery   \n",
       "9  energy,message-machine-2014,voting-record           duey-stroebel   \n",
       "\n",
       "                speaker_title      State party_affiliation  barely_true  \\\n",
       "0        State representative      Texas        republican          0.0   \n",
       "1              State delegate   Virginia          democrat          0.0   \n",
       "2                   President   Illinois          democrat         70.0   \n",
       "3                         NaN        NaN              none          7.0   \n",
       "4                         NaN    Florida          democrat         15.0   \n",
       "5  Wisconsin Assembly speaker  Wisconsin        republican          0.0   \n",
       "6                         NaN      Texas        republican          3.0   \n",
       "7                   President   Illinois          democrat         70.0   \n",
       "8                         NaN        NaN      organization          0.0   \n",
       "9        State representative  Wisconsin        republican          0.0   \n",
       "\n",
       "   false  half_true  mostly_true  pants_on_fire  \\\n",
       "0    1.0        0.0          0.0            0.0   \n",
       "1    0.0        1.0          1.0            0.0   \n",
       "2   71.0      160.0        163.0            9.0   \n",
       "3   19.0        3.0          5.0           44.0   \n",
       "4    9.0       20.0         19.0            2.0   \n",
       "5    3.0        2.0          5.0            1.0   \n",
       "6    1.0        1.0          3.0            1.0   \n",
       "7   71.0      160.0        163.0            9.0   \n",
       "8    0.0        1.0          0.0            1.0   \n",
       "9    0.0        0.0          1.0            0.0   \n",
       "\n",
       "                                    context  \n",
       "0                                  a mailer  \n",
       "1                           a floor speech.  \n",
       "2                                    Denver  \n",
       "3                            a news release  \n",
       "4                       an interview on CNN  \n",
       "5                 a an online opinion-piece  \n",
       "6                          a press release.  \n",
       "7  a Democratic debate in Philadelphia, Pa.  \n",
       "8                                a website   \n",
       "9                           an online video  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['statement'] = train_df['statement'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['statement'] = train_df['statement'].apply(lambda x: x.lower())\n",
    "train_df['statement'] = train_df['statement'].str.replace('[^\\w\\s]','')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    says annies list political group supports thir...\n",
       "1    when decline coal start it started natural gas...\n",
       "2    hillary clinton agrees john mccain by voting g...\n",
       "3    health care reform legislation likely mandate ...\n",
       "4             the economic turnaround started end term\n",
       "Name: statement, dtype: object"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "st = PorterStemmer()\n",
    "train_df['statement'][:5].apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
    "train_df['statement'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    say annies list political group support thirdt...\n",
       "1    when decline coal start it started natural gas...\n",
       "2    hillary clinton agrees john mccain by voting g...\n",
       "3    health care reform legislation likely mandate ...\n",
       "4             the economic turnaround started end term\n",
       "Name: statement, dtype: object"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "train_df['statement'] = train_df['statement'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "train_df['statement'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    say annies list political group support thirdt...\n",
       "1    when decline coal start it started natural gas...\n",
       "2    hillary clinton agrees john mccain by voting g...\n",
       "3    health care reform legislation likely mandate ...\n",
       "4             the economic turnaround started end term\n",
       "Name: statement, dtype: object"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['statement'] = train_df['statement'].replace('[^a-zA-Z0-9]', ' ', regex = True)\n",
    "train_df['statement'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    say annies list political group support thirdt...\n",
       "1    when decline coal start it started natural gas...\n",
       "2    hillary clinton agrees john mccain by voting g...\n",
       "3    health care reform legislation likely mandate ...\n",
       "4             the economic turnaround started end term\n",
       "5    the chicago bear starting quarterback last  ye...\n",
       "6        jim dunnam lived district represents year now\n",
       "7    im person stage worked actively last year pass...\n",
       "8    however took  million oregon lottery fund port...\n",
       "9    say gop primary opponent glenn grothman joe le...\n",
       "Name: statement, dtype: object"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['statement'] = train_df['statement'].replace('\\d+', '', regex = True)\n",
    "train_df['statement'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    say annies list political group support thirdt...\n",
       "1    when decline coal start it started natural gas...\n",
       "2    hillary clinton agrees john mccain by voting g...\n",
       "3    health care reform legislation likely mandate ...\n",
       "4             the economic turnaround started end term\n",
       "5    the chicago bear starting quarterback last  ye...\n",
       "6        jim dunnam lived district represents year now\n",
       "7    im person stage worked actively last year pass...\n",
       "8    however took  million oregon lottery fund port...\n",
       "9    say gop primary opponent glenn grothman joe le...\n",
       "Name: statement, dtype: object"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['statement'] = train_df['statement'].replace('\\s{2,}', '')\n",
    "train_df['statement'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline \n",
    "y = train_df_1.label \n",
    " \n",
    "# Drop the `label` column \n",
    "train_df_1.drop(\"label\", axis=1) \n",
    " \n",
    "# Make training and test sets \n",
    "#X_train, X_test, y_train, y_test = train_test_split(train_df_1['statement'], y, test_size=0.33, random_state=53)\n",
    "X_train = train_df['statement']\n",
    "X_test = test_df['statement']\n",
    "y_train = train_df.label\n",
    "y_test = test_df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(vocabulary = sensationalist_phrases_vocab,norm='l2',ngram_range = (1,3),use_idf=True, smooth_idf=True,\n",
    "                sublinear_tf=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10240, 102)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Assassination': 0,\n",
       " 'Attack': 1,\n",
       " 'Domestic security': 2,\n",
       " 'Law enforcement': 3,\n",
       " 'Disaster': 4,\n",
       " 'National preparedness': 5,\n",
       " 'Response': 6,\n",
       " 'Recovery': 7,\n",
       " 'Emergency response': 8,\n",
       " 'First responder': 9,\n",
       " 'Militia': 10,\n",
       " 'Shooting': 11,\n",
       " 'Evacuation': 12,\n",
       " 'Hostage': 13,\n",
       " 'Explosion': 14,\n",
       " 'Organized crime': 15,\n",
       " 'Gangs': 16,\n",
       " 'National security': 17,\n",
       " 'State of emergency': 18,\n",
       " 'Security breach': 19,\n",
       " 'Threat': 20,\n",
       " 'Standoff': 21,\n",
       " 'Lockdown': 22,\n",
       " 'Bomb': 23,\n",
       " 'Riot': 24,\n",
       " 'Emergency Landing': 25,\n",
       " 'Incident': 26,\n",
       " 'Suspicious': 27,\n",
       " 'Nuclear threat': 28,\n",
       " 'Hazardous': 29,\n",
       " 'Infection': 30,\n",
       " 'Outbreak': 31,\n",
       " 'Contamination': 32,\n",
       " 'Terror': 33,\n",
       " 'Epidemic': 34,\n",
       " 'Critical Infrastructure': 35,\n",
       " 'National infrastructure': 36,\n",
       " 'Transportation security': 37,\n",
       " 'Grid': 38,\n",
       " 'Outage': 39,\n",
       " 'Disruption': 40,\n",
       " 'Violence': 41,\n",
       " 'Drug cartel': 42,\n",
       " 'Narcotics': 43,\n",
       " 'Shootout': 44,\n",
       " 'Trafficking': 45,\n",
       " 'Kidnap': 46,\n",
       " 'Illegal': 47,\n",
       " 'Smuggling': 48,\n",
       " 'Al Qaeda': 49,\n",
       " 'Terror attack': 50,\n",
       " 'Weapon': 51,\n",
       " 'Improvised explosive device': 52,\n",
       " 'Suicide bomber': 53,\n",
       " 'Suicide attack': 54,\n",
       " 'Hurricane': 55,\n",
       " 'Tornado': 56,\n",
       " 'Tsunami': 57,\n",
       " 'Earthquake': 58,\n",
       " 'Tremor': 59,\n",
       " 'Flood': 60,\n",
       " 'Storm': 61,\n",
       " 'Extreme weather': 62,\n",
       " 'Forest fire': 63,\n",
       " 'Ice': 64,\n",
       " 'Stranded': 65,\n",
       " 'Wildfire': 66,\n",
       " 'Avalanche': 67,\n",
       " 'Blizzard': 68,\n",
       " 'Lightening': 69,\n",
       " 'Emergency Broadcast System': 70,\n",
       " 'Cyber Security': 71,\n",
       " 'DDOS': 72,\n",
       " 'Denial of service': 73,\n",
       " 'Malware': 74,\n",
       " 'Phishing': 75,\n",
       " 'Cyber attack': 76,\n",
       " 'Cyber terror': 77,\n",
       " 'believe': 78,\n",
       " 'support': 79,\n",
       " 'ISIS': 80,\n",
       " 'absolutely': 81,\n",
       " 'promise': 82,\n",
       " 'society': 83,\n",
       " 'FBI': 84,\n",
       " 'declare': 85,\n",
       " 'war': 86,\n",
       " 'islam': 87,\n",
       " 'recession': 88,\n",
       " 'price': 89,\n",
       " 'stock market': 90,\n",
       " 'lottery': 91,\n",
       " 'terror': 92,\n",
       " 'sanctoin': 93,\n",
       " 'ban': 94,\n",
       " 'signed': 95,\n",
       " 'climate change': 96,\n",
       " 'global warming': 97,\n",
       " 'killed': 98,\n",
       " 'shooting': 99,\n",
       " 'gun fire': 100,\n",
       " 'nuclear': 101}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 79)\t1.0\n",
      "  (8, 91)\t1.0\n",
      "  (28, 99)\t1.0\n",
      "  (37, 101)\t1.0\n",
      "  (43, 95)\t1.0\n",
      "  (73, 86)\t1.0\n",
      "  (75, 88)\t1.0\n",
      "  (78, 79)\t1.0\n",
      "  (95, 79)\t1.0\n",
      "  (98, 86)\t1.0\n",
      "  (104, 92)\t1.0\n",
      "  (138, 79)\t0.6002262913313283\n",
      "  (138, 78)\t0.7998302314833063\n",
      "  (144, 101)\t1.0\n",
      "  (147, 94)\t1.0\n",
      "  (151, 79)\t1.0\n",
      "  (159, 96)\t1.0\n",
      "  (176, 86)\t1.0\n",
      "  (177, 89)\t1.0\n",
      "  (197, 96)\t1.0\n",
      "  (201, 86)\t1.0\n",
      "  (202, 98)\t1.0\n",
      "  (216, 79)\t1.0\n",
      "  (226, 86)\t1.0\n",
      "  (238, 79)\t1.0\n",
      "  :\t:\n",
      "  (9993, 79)\t1.0\n",
      "  (10007, 81)\t1.0\n",
      "  (10008, 97)\t1.0\n",
      "  (10014, 96)\t1.0\n",
      "  (10016, 79)\t1.0\n",
      "  (10028, 89)\t1.0\n",
      "  (10034, 94)\t1.0\n",
      "  (10037, 101)\t1.0\n",
      "  (10039, 94)\t1.0\n",
      "  (10050, 89)\t1.0\n",
      "  (10061, 83)\t1.0\n",
      "  (10065, 98)\t1.0\n",
      "  (10069, 95)\t1.0\n",
      "  (10092, 86)\t1.0\n",
      "  (10129, 82)\t1.0\n",
      "  (10135, 79)\t1.0\n",
      "  (10172, 86)\t1.0\n",
      "  (10174, 98)\t1.0\n",
      "  (10178, 78)\t1.0\n",
      "  (10181, 101)\t1.0\n",
      "  (10191, 79)\t1.0\n",
      "  (10192, 79)\t1.0\n",
      "  (10216, 97)\t1.0\n",
      "  (10217, 101)\t1.0\n",
      "  (10222, 86)\t1.0\n"
     ]
    }
   ],
   "source": [
    "print(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Research shows vast majority arriving immigrants today come believe government source prosperity, thats support.'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_1['statement'][138]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6002262913313283"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "cos_doc1 = 1 - spatial.distance.cosine(tfidf[0].toarray(), tfidf[138].toarray())\n",
    "cos_doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2123125493291239\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "nb_pipeline = Pipeline([('NBCV',vectorizer),('nb_clf',MultinomialNB())])\n",
    "\n",
    "nb_pipeline.fit(X_train,y_train)\n",
    "predicted_nb = nb_pipeline.predict(X_test)\n",
    "print(np.mean(predicted_nb == y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
